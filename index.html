<!DOCTYPE html>
<!--
  Copyright 2010 Google Inc.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.

  Original slides: Marcin Wichary (mwichary@google.com)
  Modifications: Ernest Delgado (ernestd@google.com)
                 Alex Russell (slightlyoff@chromium.org)

  landslide modifications: Adam Zapletal (adamzap@gmail.com)
                           Nicolas Perriault (nperriault@gmail.com)
-->
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>None</title>
    <!-- Styles -->
    
    <link rel="stylesheet" media="print" href="theme/css/print.css">
    <link rel="stylesheet" media="screen, projection" href="theme/css/screen.css">
    
    
    <!-- /Styles -->
    <!-- Javascripts -->
    
    <script type="text/javascript" src="theme/js/slides.js"></script>
    
    
    <!-- /Javascripts -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          processEscapes: true
        },
        "HTML-CSS": { availableFonts: ["TeX"] }
      });
    </script>
    <script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</head>
<body style="!important;">
  <div id="blank"></div>
  <div class="presentation">
    <div id="current_presenter_notes">
      <div id="presenter_note"></div>
    </div>
    <div class="slides">
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><div style="border-radius: 10px; background: #EEEEEE; padding: 20px; text-align: center; font-size: 1.5em">
  <big><b>Spark for Data Scientists</b></big> </br>
  </br>

  <code>{chris,jason}@datascience.com</code>
  <br/>
  <br/>

</div></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              1/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Resources</h1></header>
            
            
            <section><ul>
<li><a href="http://spark.apache.org/documentation.html">Spark Project Docs</a></li>
<li>Karau et al's <a href="http://shop.oreilly.com/product/0636920028512.do">Learning Spark: Lightning-Fast Big Data Analysis</a></li>
<li>This course's <a href="https://github.com/cem3394/spark-for-data-scientists/tree/gh-pages">Github Project</a></li>
</ul></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              2/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Lecture 1: The Spark Ecosystem</h1></header>
            
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              3/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Matei Zaharia</h1></header>
            
            
            <section><p><img alt="" src="img/matei_zaharia.jpg" />
$$
$$
"One of the Spark project goals was to deliver a platform that supports a very wide array of diverse workflows - not only MapReduce batch jobs (there were available in Hadoop already at that time), but also iterative computations like graph algorithms or Machine Learning. And also different scales of workloads from sub-second interactive jobs to jobs that run for many hours."</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              4/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Hadoop for your RAM</h1></header>
            
            
            <section><p>Apache Spark is an open-source, parallel, distributed, general-purpose cluster computing framework with distributed, in-memory data processing.
$$
$$
In contrast to Hadoop’s two-stage disk-based MapReduce processing engine, Spark’s multi-stage in-memory computing engine allows for running most computations in memory, and hence provides better performance for iterative applications, e.g. machine learning algorithms and interactive data mining.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              5/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>A Bit of History</h1></header>
            
            
            <section><p><img alt="" src="img/history.png" /></p>
<p><a href="https://medium.com/@markobonaci/the-history-of-hadoop-68984a11704">https://medium.com/@markobonaci/the-history-of-hadoop-68984a11704</a></p>
<p class="notes">https://www.youtube.com/watch?v=SxAxAhn-BDU</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              6/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>OpenMP (1997)</h1></header>
            
            
            <section><p><img alt="" src="img/OpenMP.jpg" /></p>
<p class="notes">started w/ Backus' Fortran 1.0 in 1997. parallel processing only done on expensive supercomputers. complex and not robust to node failures.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              7/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>MapReduce (2004)</h1></header>
            
            
            <section><p><img alt="" src="img/mapreduce.png" /></p>
<p class="notes">combined FP primitives with world-class cluster computing know-how. the simple MR framework (read Backus) meant that all of a sudden it became relatively simple and reliable to compute with large arrays of cheap nodes, any of which might fail. these guys are legends. they are also behind tensorFlow.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              8/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>Hadoop (2006)</h1></header>
            
            
            <section><p><img alt="" src="img/hadoop-ecosystem.png" /></p>
<p class="notes">open source MapReduce. became a top level apache project in 2006. batched processing. static pageRank anecdote. by 2006 google had already moved on to streaming.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              9/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>SMACK (2014)</h1></header>
            
            
            <section><p><img alt="" src="img/smack-stack.jpg" /></p>
<p class="notes"> Kafka takes care to event transport, Cassandra is used to persist and distribute events. While Spark and Akka can be combined to build various data analysis pipelines for both large data sets, event processing, in order to meet the required throughput, and latency constraints. Mesos serves as a task coordinator, facilitating the distribution of tasks and jobs in the cluster.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              10/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>Why Scala: Productivity</h1></header>
            
            
            <section><p>Spark is essentially distributed Scala (<code>sc.parallelize(0 to 100)</code>). Basic syntax and Collections API are all that's needed to become productive.
$$
$$
You use the same language (often the same code) for iterative exploration as you do for large jobs.</p>
<p class="notes"> Framework and language have converged. Scala Collections API, Spark API, Scalding API, Kafka API are almost identical. Python and R are second-class citizens.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              11/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>Why Scala: Ecosystem</h1></header>
            
            
            <section><p>Scala integrates well with the big data ecosystem, which is also JVM based.
$$
$$
In addition to Scala-native frameworks like Spark and Kafka, there are many successful projects on top of mixed Java / Scala frameworks:</p>
<p class="notes">Scalding (Cascading), Algebird / Summingbird (Scalding and Spark), Finagle (Akka), Scrunch (Crunch), Flink (Java and Scala)</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              12/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Why Scala: Functional Paradigm</h1></header>
            
            
            <section><p>A third benefit is the functional paradigm which fits well within the Map/Reduce and big data model.
$$
$$
Batch processing works on top of immutable data, transforms with combinators, and generates new copies. Real time log streams are essentially lazy streams.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              13/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>Most Scala data frameworks have the notion of some abstract data type that's extremely consistent with Scala's collection API.
$$
$$
Glance at <code>TypedPipe</code> in Scalding and <code>RDD</code> in Spark, and you'll see that they all have the same set of combinator methods, e.g. <code>map</code>, <code>flatMap</code>, <code>filter</code>, <code>reduce</code>, <code>fold</code> and <code>groupBy</code>.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              14/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>Spark libraries also have frequent reference of category theory (eg monoids, monads, applicative functors etc) to guarantee the correctness of distributed operations.
$$
$$
Equipped with this knowledge it will be a lot easier to understand techniques like map-side joins and reduces.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              15/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_code has_notes">
          <div class="inner">
            
            <header><h1>Hello World in Spark</h1></header>
            
            
            <section><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span> <span class="s">&quot;1950.txt&quot;</span> <span class="o">)</span>
<span class="n">lines</span><span class="o">.</span><span class="n">flatMap</span><span class="o">(</span> <span class="o">(</span><span class="n">l</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot; &quot;</span><span class="o">)</span> <span class="o">)</span>
 <span class="o">.</span><span class="n">map</span><span class="o">(</span> <span class="o">(</span><span class="n">w</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">w</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span> <span class="o">)</span>
 <span class="o">.</span><span class="n">reduceByKey</span><span class="o">(</span> <span class="k">_</span> <span class="o">+</span> <span class="k">_</span> <span class="o">)</span>
 <span class="o">.</span><span class="n">saveAsTextFile</span><span class="o">(</span> <span class="s">&quot;WordCount.txt&quot;</span> <span class="o">)</span>
</pre></div>

<p class="notes">this code looks fairly unremarkable, as if map and reduce are simply part of the core language.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              16/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>Spark Stack</h1></header>
            
            
            <section><p><img alt="" src="img/spark-ecosystem.png" /></p>
<p class="notes">Spark can run over a variety of cluster managers, including Hadoop YARN, Apache Mesos, and a Standalone Scheduler. SparkSQL Spark’s package for working with structured data (DataFrames) and semi-structured data (DataSets). Spark Streaming is a Spark component that enables processing of live streams of data. GraphX is a library for manipulating graphs and performing graph-parallel computations (We will cover these in the Methods class). Spark's machine learning library (We will cover MLlib in the Models class). Spark Core contains the basic functionality of Spark: task scheduling, memory management, fault recovery, interacting with storage systems, etc. The RDD API will be our point of departure in this course.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              17/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>Benefits of Tight Integration</h1></header>
            
            
            <section><ul>
<li>
<p>Higher-level components in the stack benefit from improvements at the lower layers</p>
</li>
<li>
<p>Organizational costs associated with running the stack are minimized</p>
</li>
<li>
<p>Combine batch, interactive, and stream processing processing with a unified API</p>
</li>
</ul>
<p class="notes">For example, when Spark’s core engine adds an optimization, SQL and machine learning libraries automatically speed up as well. These costs include deployment, maintenance, testing, support, and others. This also means that each time a new component is added to the Spark stack, every organization that uses Spark will immediately be able to try this new component. Spark’s design is also fairly simple and the Scala codebase is fairly small relative to the features it offers.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              18/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            <header><h1>Computation Model</h1></header>
            
            
            <section><p>Spark supports diverse workloads, but is optimized for low-latency iterative tasks.
$$
$$
These sorts of computation occur often in Machine Learning and graph algorithms.</p>
<p class="notes">Many Machine Learning algorithms require plenty of iterations before the result models get optimal, like logistic regression. The same applies to graph algorithms to traverse all the nodes and edges when needed. Iterative computations can increase their performance when the interim partial results are stored in memory. Spark can cache intermediate data in memory for faster model building and training.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              19/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>Spark creates a <em>directed acyclic graph</em> (DAG) of computation stages to submit jobs to the cluster manager.
$$
$$
Spark uses a <em>lazy evaluation model</em> (i.e. postpones any processing until an action is performed).</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              20/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_code">
          <div class="inner">
            
            
            <section><div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">lines</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;1950.txt&quot;</span><span class="o">)</span> <span class="c1">//creation</span>
<span class="k">val</span> <span class="n">nyt</span> <span class="k">=</span> <span class="s">&quot;Special to THE NEW YORK TIMES.&quot;</span>
<span class="k">val</span> <span class="n">linesWithNYT</span> <span class="k">=</span> <span class="n">lines</span><span class="o">.</span><span class="n">filter</span> <span class="o">{</span><span class="k">_</span> <span class="n">contains</span> <span class="n">nyt</span><span class="o">}</span> <span class="c1">//transformation</span>
<span class="n">linesWithNYT</span><span class="o">.</span><span class="n">count</span><span class="o">()</span> <span class="c1">//action</span>
</pre></div>
</section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              21/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Spark and Hadoop</h1></header>
            
            
            <section><p>$$
$$</p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;margin:0px auto;}
.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}
.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}
.tg .tg-9hbo{font-weight:bold;vertical-align:top}
.tg .tg-yw4l{vertical-align:top}
</style>

<table class="tg">
  <tr>
    <th class="tg-9hbo"></th>
    <th class="tg-9hbo">RDD</th>
    <th class="tg-9hbo">DSM</th>
  </tr>
  <tr>
    <td class="tg-9hbo">Evaluation</td>
    <td class="tg-yw4l">lazy</td>
    <td class="tg-yw4l">strict</td>
  </tr>
  <tr>
    <td class="tg-9hbo">Writes</td>
    <td class="tg-yw4l">coarse grained</td>
    <td class="tg-yw4l">fine grained</td>
  </tr>
  <tr>
    <td class="tg-9hbo">Recovery</td>
    <td class="tg-yw4l">lineage</td>
    <td class="tg-yw4l">check point</td>
  </tr>
  <tr>
    <td class="tg-9hbo">Consistency</td>
    <td class="tg-yw4l">trivial / immutable</td>
    <td class="tg-yw4l">delegated</td>
  </tr>
</table>

<!---it is indeed possible to write concurrent programs in imperative and OO languages, but it's extremely painful. In essence, you have to translate functional methods to your language of choice and follow the functional paradigm religiously. A single slip and you're spending weeks tracking concurrency bugs.
The reason is that, in imperative languages, and OO in particular, the sharing of data is the default behavior. And sharing of data between threads leads to data races -- unless you follow a very strict regime of synchronization. No help from the compiler or the type system! All the methodologies of testing and bug reporting fail miserably in the face of data races. It's usually very hard to reproduce a non-trivial concurrency bug.
In strict functional languages, sharing and mutation are closely monitored through the type system. By default, all data is immutable, and therefore can be freely shared. Mutable data is encapsulated in a way that cannot be escaped. If a function does mutation, this fact is reflected in its type -- and in the type of all functions that call it.
Then there is the issue of STM (Software Transactional Memory) -- the most foolproof method of writing concurrent code. An atomic STM section of code is forbidden to perform any I/O because, if it's retried, it will perform it multiple times. In imperative languages, the burden of proof (that the atomic section does no I/O) is on the programmer. In Haskell, this behavior is forbidden by the type system: STM and IO monads don't mix. That's why STM works great in Haskell, while the attempts to introduce it in C++ have been, so far, unsuccessful.--></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              22/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_notes">
          <div class="inner">
            
            
            <section><p><img alt="" src="img/spark-vs-hadoop.png" />
$$
$$
Duration of the first and later iterations in Hadoop, HadoopBinMem and Spark for logistic regression and k-means using 100 GB of data on a 100-node cluster.
<a href="https://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf">source</a></p>
<p class="notes">Hadoop: The Hadoop 0.20.2 stable release. HadoopBinMem: A Hadoop deployment that converts the input data into a low-overhead binary format in the first iteration to eliminate text parsing in later ones, and stores it in an in-memory HDFS instance.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              23/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source:  -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="page_number">
              /51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Spark Context</h1></header>
            
            
            <section><p>At a high level, every Spark application consists of a driver that launches various parallel operations on a cluster.
$$
$$
The driver program contains your application’s main function and defines distributed datasets on the cluster, then applies operations to them.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              24/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>Driver programs access Spark through a <code>SparkContext</code> object, which represents a connection to a computing cluster.
$$
$$
A Spark context is essentially a client of Spark’s execution environment and acts as the director of your Spark application.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              25/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p><code>SparkContext</code> in turn requires a <code>SparkConf</code> object for configuration.
$$
$$
Refer to <a href="http://spark.apache.org/docs/latest/configuration.html">Spark Configuration</a> for further discussion of how to configure Spark.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              26/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>SparkContext offers a lot of functionality, for example:</p>
<ul>
<li>Creating / deleting RDDs</li>
<li>Setting # of RDD partitions</li>
<li>Creating accumulators</li>
<li>Creating broadcast variables</li>
<li>Distributing JARs to workers</li>
<li>Accessing services, e.g. Task Scheduler, DAGScheduler, Listener Bus, Block Manager, Shuffle Manager.</li>
<li>Closure Cleaning</li>
<li>Running jobs</li>
</ul></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              27/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Running jobs</h1></header>
            
            
            <section><p>All RDD actions in Spark launch jobs (that are run on one or many partitions of the RDD) using <code>SparkContext.runJob(rdd: RDD[T], func: Iterator[T] =&gt; U): Array[U]</code>.
$$
$$
Running a job is essentially executing a function on all or a subset of partitions in an RDD and returning the result as an array (with elements being the results per partition).</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              28/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Challenge Question</h1></header>
            
            
            <section><p>Run a job using <code>runJob</code> on the <code>lines</code> RDD with a function that returns 1 for every partition.
$$
$$
What can you say about the number of partitions of the lines RDD?</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              29/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source:  -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="page_number">
              /51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_code">
          <div class="inner">
            
            
            <section><p>Now run the following code. Is your result different than before? Why?</p>
<div class="highlight"><pre><span></span><span class="k">val</span> <span class="n">foo</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="mi">0</span> <span class="n">to</span> <span class="mi">10</span><span class="o">)</span>
<span class="n">sc</span><span class="o">.</span><span class="n">runJob</span><span class="o">(</span><span class="n">foo</span><span class="o">,</span> <span class="o">(</span><span class="n">t</span><span class="k">:</span> <span class="kt">TaskContext</span><span class="o">,</span> <span class="n">i</span><span class="k">:</span> <span class="kt">Iterator</span><span class="o">[</span><span class="kt">Int</span><span class="o">])</span> <span class="k">=&gt;</span> <span class="mi">1</span><span class="o">)</span>
</pre></div>
</section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              30/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>A job  is a top-level work item (computation) submitted to <code>DAGScheduler</code> to compute the result of an action.
$$
$$
Computing a job is equivalent to computing the partitions of the RDD the action has been executed upon.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              31/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>WebUI</h1></header>
            
            
            <section><p>Spark comes with Web UI (aka webUI) to inspect job executions using a browser.</p>
<p>Every SparkContext launches its own instance of Web UI, available at <a href="http://localhost:4040/">http://[master]:4040</a> by default (the port can be changed using <code>spark.ui.port</code>).</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              32/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>It offers tabs with the following information:</p>
<ul>
<li>Jobs</li>
<li>Stages</li>
<li>Storage (with RDD size and memory use)</li>
<li>Environment</li>
<li>Executors</li>
<li>SQL</li>
</ul>
<p>You can view the web UI after the fact after setting spark.eventLog.enabled to true before starting the application.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              33/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_code has_notes">
          <div class="inner">
            
            
            <section><p>For standalone applications you must create your own Spark context.</p>
<div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
<span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setMaster</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
                          <span class="o">.</span><span class="n">setAppName</span><span class="o">(</span><span class="s">&quot;My App&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">sc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="o">(</span><span class="n">conf</span><span class="o">)</span>
</pre></div>

<p class="notes">In Zeppelin, the driver program is the Spark interpreter itself.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              34/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>The cluster URL tells Spark how to connect to a cluster. local is a special value that runs Spark on one thread on the local machine, without connecting to a cluster.
$$
$$
The application name identifies your application to the cluster manager.
$$
$$
Note that only one SparkContext may be running in a single JVM (check out <a href="https://issues.apache.org/jira/browse/SPARK-2243">SPARK-2243 Support multiple SparkContexts in the same JVM</a>)</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              35/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_code has_notes">
          <div class="inner">
            
            <header><h1>Building and Submitting Executables</h1></header>
            
            
            <section><p>We can build applications using Scala / JVM tools like Gradle, Maven, or <code>sbt</code>:</p>
<div class="highlight"><pre><span></span><span class="n">name</span> <span class="o">:=</span> <span class="s">&quot;hello-world&quot;</span>
<span class="n">version</span> <span class="o">:=</span> <span class="s">&quot;0.0.1&quot;</span>
<span class="n">scalaVersion</span> <span class="o">:=</span> <span class="s">&quot;2.10.4&quot;</span>
<span class="c1">// additional libraries</span>
<span class="n">libraryDependencies</span> <span class="o">++=</span> <span class="nc">Seq</span><span class="o">(</span>
 <span class="s">&quot;org.apache.spark&quot;</span> <span class="o">%%</span> <span class="s">&quot;spark-core&quot;</span> <span class="o">%</span> <span class="s">&quot;1.2.0&quot;</span> <span class="o">%</span> <span class="s">&quot;provided&quot;</span>
<span class="o">)</span>
</pre></div>

<p class="notes">We'll learn about how to do this using sbt in lab.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              36/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1><code>spark-submit</code></h1></header>
            
            
            <section><p>Once you have your build defined, you can use <code>spark-submit</code> to submit it to a Spark deployment environment.
$$
$$
You'll find <code>spark-submit</code> in <code>bin</code> directory of the Spark distribution.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              37/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Spark Shell</h1></header>
            
            
            <section><p>Spark shell is an interactive shell for learning about Apache Spark, ad-hoc queries and developing Spark applications.
$$
$$
It is a very convenient tool to explore Spark and one of the many reasons why Spark is so helpful even for very simple tasks.
$$
$$
There are two main variants: <code>spark-shell</code> for Scala and <code>pyspark</code> for Python.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              38/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>You start Spark shell using spark-shell script (available in bin directory).</p>
<pre><code>$ ./bin/spark-shell
Spark context available as sc.
SQL context available as sqlContext.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 1.6.0-SNAPSHOT
      /_/
</code></pre></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              39/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>When you execute spark-shell it executes Spark submit as follows:
$$
$$
<code>org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name Spark shell spark-shell</code>
$$
$$
Set <code>SPARK_PRINT_LAUNCH_COMMAND</code> to see the entire command to be executed.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              40/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>Spark shell gives you the <code>sc</code> value which is the <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.SparkContext">SparkContext</a> for the session.</p>
<pre><code>scala&gt; sc
res0: spark.SparkContext = spark.SparkContext@2ac0cb64
</code></pre></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              41/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>You can query for the values of Spark properties in Spark shell as follows:</p>
<pre><code>scala&gt; sc.getConf.getOption("spark.local.dir")
res1: Option[String] = None
scala&gt; sc.getConf.getOption("spark.app.name")
res2: Option[String] = Some(Spark shell)
</code></pre></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              42/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>There is also an <code>sqlContext</code> object to use with Spark SQL.</p>
<pre><code>scala&gt; sqlContext
res1: spark.sql.SQLContext = spark.sql.hive.HiveContext@60ae950f
</code></pre></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              43/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>To close Spark shell, you press Ctrl+D or type in <code>:q</code> (or any subset of <code>:quit</code>).</p>
<pre><code>scala&gt; :quit
</code></pre></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              44/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>Lecture 2: RDD's</h1></header>
            
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              45/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            <header><h1>RDD - Resilient Distributed Dataset</h1></header>
            
            
            <section><p>Resilient Distributed Dataset (RDD) is the primary data abstraction in Spark. It is a distributed collection of items.</p>
<p>The original paper is a great read: <a href="https://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf">https://www.cs.berkeley.edu/~matei/papers/2012/nsdi_spark.pdf</a></p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              46/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>You use a Spark context to create RDDs.
$$
$$
When an RDD is created, it belongs to and is completely owned by the Spark context it originated from. RDDs can’t by design be shared between SparkContexts.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              47/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>At a high level, any Spark application creates RDDs out of some input, run (lazy) transformations of these RDDs to some other form (shape), and finally perform actions to collect or store data.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              48/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_code">
          <div class="inner">
            
            <header><h1>Transformations</h1></header>
            
            
            <section><div class="highlight"><pre><span></span><span class="k">def</span> <span class="n">map</span><span class="o">[</span><span class="kt">U</span><span class="o">](</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="n">U</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">U</span><span class="o">]</span>
<span class="k">def</span> <span class="n">flatMap</span><span class="o">[</span><span class="kt">U</span><span class="o">](</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="nc">Seq</span><span class="o">[</span><span class="kt">U</span><span class="o">]</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">U</span><span class="o">]</span>
<span class="k">def</span> <span class="n">filter</span><span class="o">(</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="nc">Boolean</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">keyBy</span><span class="o">[</span><span class="kt">K</span><span class="o">](</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="n">K</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">K</span>,<span class="kt">T</span><span class="o">)]</span>
<span class="k">def</span> <span class="n">groupBy</span><span class="o">[</span><span class="kt">K</span><span class="o">](</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="n">K</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">K</span>,<span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])]</span>
<span class="k">def</span> <span class="n">sortBy</span><span class="o">[</span><span class="kt">K</span><span class="o">](</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="n">K</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">distinct</span><span class="o">(</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">intersection</span><span class="o">(</span> <span class="n">rdd</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">subtract</span><span class="o">(</span> <span class="n">rdd</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">union</span><span class="o">(</span> <span class="n">rdd</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">cartesian</span><span class="o">[</span><span class="kt">U</span><span class="o">](</span> <span class="n">rdd</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">U</span><span class="o">]</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">T</span>,<span class="kt">U</span><span class="o">)]</span>
<span class="k">def</span> <span class="n">zip</span><span class="o">[</span><span class="kt">U</span><span class="o">](</span> <span class="n">rdd</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">U</span><span class="o">]</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">RDD</span><span class="o">[(</span><span class="kt">T</span>,<span class="kt">U</span><span class="o">))</span>
<span class="k">def</span> <span class="n">sample</span><span class="o">(</span> <span class="n">r</span><span class="k">:</span><span class="kt">Boolean</span><span class="o">,</span> <span class="n">f</span><span class="k">:</span><span class="kt">Double</span><span class="o">,</span> <span class="n">s</span><span class="k">:</span><span class="kt">Long</span> <span class="o">)</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">pipe</span><span class="o">(</span><span class="n">command</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span>
</pre></div>
</section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              49/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide has_code">
          <div class="inner">
            
            <header><h1>Actions</h1></header>
            
            
            <section><div class="highlight"><pre><span></span><span class="c1">// Trigger execution of DAG.</span>
<span class="k">def</span> <span class="n">foreach</span><span class="o">(</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">)</span> <span class="o">=&gt;</span> <span class="nc">Unit</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">Unit</span>    
<span class="k">def</span> <span class="n">reduce</span><span class="o">(</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">,</span><span class="kt">T</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">T</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">T</span>
<span class="k">def</span> <span class="n">fold</span><span class="o">(</span><span class="n">z</span><span class="k">:</span><span class="kt">T</span><span class="o">)(</span> <span class="n">f</span><span class="k">:</span><span class="o">(</span><span class="kt">T</span><span class="o">,</span><span class="kt">T</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">T</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">T</span>
<span class="k">def</span> <span class="n">min</span><span class="o">()</span> <span class="k">:</span> <span class="kt">T</span>
<span class="k">def</span> <span class="n">max</span><span class="o">()</span> <span class="k">:</span> <span class="kt">T</span>
<span class="k">def</span> <span class="n">first</span><span class="o">()</span> <span class="k">:</span> <span class="kt">T</span>
<span class="k">def</span> <span class="n">count</span><span class="o">()</span> <span class="k">:</span> <span class="kt">Long</span>
<span class="k">def</span> <span class="n">countByKey</span><span class="o">()</span> <span class="k">:</span> <span class="kt">Map</span><span class="o">[</span><span class="kt">K</span>,<span class="kt">Long</span><span class="o">]</span>
<span class="k">def</span> <span class="n">collect</span><span class="o">(</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">top</span><span class="o">(</span> <span class="n">n</span><span class="k">:</span><span class="kt">Int</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">take</span><span class="o">(</span> <span class="n">n</span><span class="k">:</span><span class="kt">Int</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">takeOrdered</span><span class="o">(</span> <span class="n">n</span><span class="k">:</span><span class="kt">Int</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">takeSample</span><span class="o">(</span> <span class="n">r</span><span class="k">:</span><span class="kt">Boolean</span><span class="o">,</span> <span class="n">n</span><span class="k">:</span><span class="kt">Int</span><span class="o">,</span> <span class="n">s</span><span class="k">:</span><span class="kt">Long</span> <span class="o">)</span> <span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">T</span><span class="o">]</span>
<span class="k">def</span> <span class="n">aggregate</span><span class="o">[</span><span class="kt">U</span><span class="o">](</span><span class="n">z</span><span class="k">:</span> <span class="kt">U</span><span class="o">)(</span><span class="n">seq</span><span class="k">:</span> <span class="o">(</span><span class="kt">U</span><span class="o">,</span> <span class="kt">T</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">U</span><span class="o">,</span> <span class="n">comb</span><span class="k">:</span> <span class="o">(</span><span class="kt">U</span><span class="o">,</span> <span class="kt">U</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">U</span><span class="o">)</span><span class="k">:</span> <span class="kt">U</span>
</pre></div>
</section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              50/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source: slides.md -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
            <section><p>As we mentioned last time, RDD actions in Spark launch jobs.
$$
$$
The number of partitions in a job depends on the type of a stage - <code>ResultStage</code> or <code>ShuffleMapStage</code>.
$$
$$
A job starts with a single target RDD, but can ultimately include other RDDs that are all part of the target RDD’s lineage graph.</p></section>
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="source">
              Source: <a href="slides.md">slides.md</a>
            </aside>
            
            <aside class="page_number">
              51/51
            </aside>

          </footer>
        </div>
      </div>
      
      <!-- slide source:  -->
      <div class="slide-wrapper">
        <div class="slide">
          <div class="inner">
            
            
          </div>
          <div class="presenter_notes">
            <header><h1>Presenter Notes</h1></header>
            <section>
            
            </section>
          </div>


          <footer>
            
            <aside class="page_number">
              /51
            </aside>

          </footer>
        </div>
      </div>
      
    </div>
  </div>
  
  <div id="toc" class="sidebar hidden">
    <h2>Table of Contents</h2>
    <table>
      <caption>Table of Contents</caption>
      
      <tr id="toc-row-1">
        <th><a href="#slide1">-</a></th>
        <td><a href="#slide1">1</a></td>
      </tr>
      
      
      <tr id="toc-row-2">
        <th><a href="#slide2">Resources</a></th>
        <td><a href="#slide2">2</a></td>
      </tr>
      
      
      <tr id="toc-row-3">
        <th><a href="#slide3">Lecture 1: The Spark Ecosystem</a></th>
        <td><a href="#slide3">3</a></td>
      </tr>
      
      
      <tr id="toc-row-4">
        <th><a href="#slide4">Matei Zaharia</a></th>
        <td><a href="#slide4">4</a></td>
      </tr>
      
      
      <tr id="toc-row-5">
        <th><a href="#slide5">Hadoop for your RAM</a></th>
        <td><a href="#slide5">5</a></td>
      </tr>
      
      
      <tr id="toc-row-6">
        <th><a href="#slide6">A Bit of History</a></th>
        <td><a href="#slide6">6</a></td>
      </tr>
      
      
      <tr id="toc-row-7">
        <th><a href="#slide7">OpenMP (1997)</a></th>
        <td><a href="#slide7">7</a></td>
      </tr>
      
      
      <tr id="toc-row-8">
        <th><a href="#slide8">MapReduce (2004)</a></th>
        <td><a href="#slide8">8</a></td>
      </tr>
      
      
      <tr id="toc-row-9">
        <th><a href="#slide9">Hadoop (2006)</a></th>
        <td><a href="#slide9">9</a></td>
      </tr>
      
      
      <tr id="toc-row-10">
        <th><a href="#slide10">SMACK (2014)</a></th>
        <td><a href="#slide10">10</a></td>
      </tr>
      
      
      <tr id="toc-row-11">
        <th><a href="#slide11">Why Scala: Productivity</a></th>
        <td><a href="#slide11">11</a></td>
      </tr>
      
      
      <tr id="toc-row-12">
        <th><a href="#slide12">Why Scala: Ecosystem</a></th>
        <td><a href="#slide12">12</a></td>
      </tr>
      
      
      <tr id="toc-row-13">
        <th><a href="#slide13">Why Scala: Functional Paradigm</a></th>
        <td><a href="#slide13">13</a></td>
      </tr>
      
      
      <tr id="toc-row-14">
        <th><a href="#slide14">-</a></th>
        <td><a href="#slide14">14</a></td>
      </tr>
      
      
      <tr id="toc-row-15">
        <th><a href="#slide15">-</a></th>
        <td><a href="#slide15">15</a></td>
      </tr>
      
      
      <tr id="toc-row-16">
        <th><a href="#slide16">Hello World in Spark</a></th>
        <td><a href="#slide16">16</a></td>
      </tr>
      
      
      <tr id="toc-row-17">
        <th><a href="#slide17">Spark Stack</a></th>
        <td><a href="#slide17">17</a></td>
      </tr>
      
      
      <tr id="toc-row-18">
        <th><a href="#slide18">Benefits of Tight Integration</a></th>
        <td><a href="#slide18">18</a></td>
      </tr>
      
      
      <tr id="toc-row-19">
        <th><a href="#slide19">Computation Model</a></th>
        <td><a href="#slide19">19</a></td>
      </tr>
      
      
      <tr id="toc-row-20">
        <th><a href="#slide20">-</a></th>
        <td><a href="#slide20">20</a></td>
      </tr>
      
      
      <tr id="toc-row-21">
        <th><a href="#slide21">-</a></th>
        <td><a href="#slide21">21</a></td>
      </tr>
      
      
      <tr id="toc-row-22">
        <th><a href="#slide22">Spark and Hadoop</a></th>
        <td><a href="#slide22">22</a></td>
      </tr>
      
      
      <tr id="toc-row-23">
        <th><a href="#slide23">-</a></th>
        <td><a href="#slide23">23</a></td>
      </tr>
      
      
      <tr id="toc-row-24">
        <th><a href="#slide24">Spark Context</a></th>
        <td><a href="#slide24">24</a></td>
      </tr>
      
      
      <tr id="toc-row-25">
        <th><a href="#slide25">-</a></th>
        <td><a href="#slide25">25</a></td>
      </tr>
      
      
      <tr id="toc-row-26">
        <th><a href="#slide26">-</a></th>
        <td><a href="#slide26">26</a></td>
      </tr>
      
      
      <tr id="toc-row-27">
        <th><a href="#slide27">-</a></th>
        <td><a href="#slide27">27</a></td>
      </tr>
      
      
      <tr id="toc-row-28">
        <th><a href="#slide28">Running jobs</a></th>
        <td><a href="#slide28">28</a></td>
      </tr>
      
      
      <tr id="toc-row-29">
        <th><a href="#slide29">Challenge Question</a></th>
        <td><a href="#slide29">29</a></td>
      </tr>
      
      
      <tr id="toc-row-30">
        <th><a href="#slide30">-</a></th>
        <td><a href="#slide30">30</a></td>
      </tr>
      
      
      <tr id="toc-row-31">
        <th><a href="#slide31">-</a></th>
        <td><a href="#slide31">31</a></td>
      </tr>
      
      
      <tr id="toc-row-32">
        <th><a href="#slide32">WebUI</a></th>
        <td><a href="#slide32">32</a></td>
      </tr>
      
      
      <tr id="toc-row-33">
        <th><a href="#slide33">-</a></th>
        <td><a href="#slide33">33</a></td>
      </tr>
      
      
      <tr id="toc-row-34">
        <th><a href="#slide34">-</a></th>
        <td><a href="#slide34">34</a></td>
      </tr>
      
      
      <tr id="toc-row-35">
        <th><a href="#slide35">-</a></th>
        <td><a href="#slide35">35</a></td>
      </tr>
      
      
      <tr id="toc-row-36">
        <th><a href="#slide36">Building and Submitting Executables</a></th>
        <td><a href="#slide36">36</a></td>
      </tr>
      
      
      <tr id="toc-row-37">
        <th><a href="#slide37"><code>spark-submit</code></a></th>
        <td><a href="#slide37">37</a></td>
      </tr>
      
      
      <tr id="toc-row-38">
        <th><a href="#slide38">Spark Shell</a></th>
        <td><a href="#slide38">38</a></td>
      </tr>
      
      
      <tr id="toc-row-39">
        <th><a href="#slide39">-</a></th>
        <td><a href="#slide39">39</a></td>
      </tr>
      
      
      <tr id="toc-row-40">
        <th><a href="#slide40">-</a></th>
        <td><a href="#slide40">40</a></td>
      </tr>
      
      
      <tr id="toc-row-41">
        <th><a href="#slide41">-</a></th>
        <td><a href="#slide41">41</a></td>
      </tr>
      
      
      <tr id="toc-row-42">
        <th><a href="#slide42">-</a></th>
        <td><a href="#slide42">42</a></td>
      </tr>
      
      
      <tr id="toc-row-43">
        <th><a href="#slide43">-</a></th>
        <td><a href="#slide43">43</a></td>
      </tr>
      
      
      <tr id="toc-row-44">
        <th><a href="#slide44">-</a></th>
        <td><a href="#slide44">44</a></td>
      </tr>
      
      
      <tr id="toc-row-45">
        <th><a href="#slide45">Lecture 2: RDD's</a></th>
        <td><a href="#slide45">45</a></td>
      </tr>
      
      
      <tr id="toc-row-46">
        <th><a href="#slide46">RDD - Resilient Distributed Dataset</a></th>
        <td><a href="#slide46">46</a></td>
      </tr>
      
      
      <tr id="toc-row-47">
        <th><a href="#slide47">-</a></th>
        <td><a href="#slide47">47</a></td>
      </tr>
      
      
      <tr id="toc-row-48">
        <th><a href="#slide48">-</a></th>
        <td><a href="#slide48">48</a></td>
      </tr>
      
      
      <tr id="toc-row-49">
        <th><a href="#slide49">Transformations</a></th>
        <td><a href="#slide49">49</a></td>
      </tr>
      
      
      <tr id="toc-row-50">
        <th><a href="#slide50">Actions</a></th>
        <td><a href="#slide50">50</a></td>
      </tr>
      
      
      <tr id="toc-row-51">
        <th><a href="#slide51">-</a></th>
        <td><a href="#slide51">51</a></td>
      </tr>
      
      
    </table>
  </div>
  
  <div id="help" class="sidebar hidden">
    <h2>Help</h2>
    <table>
      <caption>Help</caption>
      <tr>
        <th>Table of Contents</th>
        <td>t</td>
      </tr>
      <tr>
        <th>Exposé</th>
        <td>ESC</td>
      </tr>
      <tr>
        <th>Full screen slides</th>
        <td>e</td>
      </tr>
      <tr>
        <th>Presenter View</th>
        <td>p</td>
      </tr>
      <tr>
        <th>Source Files</th>
        <td>s</td>
      </tr>
      <tr>
        <th>Slide Numbers</th>
        <td>n</td>
      </tr>
      <tr>
        <th>Toggle screen blanking</th>
        <td>b</td>
      </tr>
      <tr>
        <th>Show/hide slide context</th>
        <td>c</td>
      </tr>
      <tr>
        <th>Notes</th>
        <td>2</td>
      </tr>
      <tr>
        <th>Help</th>
        <td>h</td>
      </tr>
    </table>
  </div>
  <script>main()</script>
</body>
</html>